{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word ladder\n",
    "\n",
    "Word ladder is a game invented by Lewis Carroll where the goal is transform one word into another by changing one letter at a time. Each intermediate word must be a valid word (in the dictionary). You should try to find the shortest possible path.\n",
    "\n",
    "We have a file, `words.txt`, that has a series of three-, four- and five-letter words from the Merriam-Webster dictionary.\n",
    "\n",
    "**Goal**: Find the shortest path between any two words.\n",
    "\n",
    "**Plan**:\n",
    "\n",
    "1. Construct a graph from all words in the corpus\n",
    "2. Perform a BFS to find the shortest path between two nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Iterator\n",
    "from collections import defaultdict, deque\n",
    "import itertools\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(a: str, b: str) -> bool:\n",
    "    n = len(a)\n",
    "    m = len(b)\n",
    "\n",
    "    diffs = 0\n",
    "    for i in range(min(n, m)):\n",
    "        if a[i] != b[i]:\n",
    "            diffs += 1\n",
    "\n",
    "    # Handle strings being different lengths\n",
    "    diffs += abs(n - m)\n",
    "\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optimise! This is so slow (takes about 3 mins on my M1 Air)\n",
    "def load_graph(filename: str) -> Dict[str, List[str]]:\n",
    "    graph = defaultdict(list)\n",
    "\n",
    "    with open(filename) as f:\n",
    "        words = f.read().splitlines()\n",
    "\n",
    "    for i in tqdm(words):\n",
    "        for j in words:\n",
    "            if i == j:\n",
    "                continue\n",
    "\n",
    "            if edit_distance(i, j) <= 1:\n",
    "                graph[i].append(j)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "graph = load_graph(\"words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_ladder(graph: Dict[str, List[str]], start: str, end: str) -> List[List[str]]:\n",
    "    \"\"\"Returns a list of shortest paths from start to end.\"\"\"\n",
    "    queue = deque([(start, [])])\n",
    "    visited = set()\n",
    "    paths: List[List[str]] = []  # a forest, TODO: track parent instead\n",
    "    shortest_path = float(\"inf\")\n",
    "\n",
    "    if start not in graph:\n",
    "        raise ValueError(f\"invalid start: {start}\")\n",
    "    if end not in graph:\n",
    "        raise ValueError(f\"invalid end: {end}\")\n",
    "\n",
    "    while queue:\n",
    "        word, path = queue.popleft()\n",
    "\n",
    "        if word == end:\n",
    "            if len(path) < shortest_path:\n",
    "                paths.clear()\n",
    "                shortest_path = len(path)\n",
    "            if len(path) <= shortest_path:\n",
    "                paths.append(path + [word])\n",
    "\n",
    "        visited.add(word)\n",
    "\n",
    "        for neighbour in graph[word]:\n",
    "            if neighbour in visited:\n",
    "                continue\n",
    "            queue.append((neighbour, path + [word]))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "word_ladder(graph, \"aba\", \"abaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "word_ladder(graph, \"head\", \"tail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "word_ladder(graph, \"pig\", \"sty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I considered an extension of the game where you can move between words of different lengths (the original version is only for words of the same length).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knuth studied this game and remarked that three- and four-letter words are not that interesting and six-letter words are too hard. Five-letter words are that sweet spot. In the dictionary he used, he found that there were 517 'aloof' words, including 'aloof' itself!\n",
    "\n",
    "> In our dictionary, 'aloof' is related to 'cloof' which has many neighbours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[\"aloof\"], graph[\"cloof\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our aloof words are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aloof_words = []\n",
    "with open(\"words.txt\") as f:\n",
    "    for word in f.read().splitlines():\n",
    "        if len(graph[word]) == 0:\n",
    "            aloof_words.append(word)\n",
    "\n",
    "len(aloof_words), aloof_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using networkx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct graph\n",
    "# Takes about three minutes (on my M1 Air)\n",
    "def load_graph(filename) -> nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    with open(filename) as f:\n",
    "        words = f.read().splitlines()\n",
    "        for i in tqdm(words):\n",
    "            for j in words:\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                if edit_distance(i, j) <= 1:\n",
    "                    G.add_edge(i, j)\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = load_graph(\"words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_ladder(G: nx.Graph, start: str, end: str) -> Iterator[List[str]]:\n",
    "    return nx.all_shortest_paths(G, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list(word_ladder(G, \"pig\", \"sty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a rough benchmark, it seems like NetworkX is ~25x faster than my own code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelising data loading\n",
    "\n",
    "1. Using threads\n",
    "2. Using processes\n",
    "3. Using Ray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(filename) -> nx.Graph:\n",
    "    def process_word_neighbours(words, word):\n",
    "        neighbours = []\n",
    "        for neighbour in words:\n",
    "            if word != neighbour and edit_distance(word, neighbour) <= 1:\n",
    "                neighbours.append((word, neighbour))\n",
    "\n",
    "        return neighbours\n",
    "\n",
    "    G = nx.Graph()\n",
    "    with open(filename) as f:\n",
    "        words = f.read().splitlines()\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for result in executor.map(\n",
    "            lambda word: process_word_neighbours(words, word), words\n",
    "        ):\n",
    "            if result:\n",
    "                G.add_edges_from(result)\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This wasn't really any faster\n",
    "G = load_graph(\"words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word_neighbours(words, word):\n",
    "    neighbours = []\n",
    "    for neighbour in words:\n",
    "        if word != neighbour and edit_distance(word, neighbour) <= 1:\n",
    "            neighbours.append((word, neighbour))\n",
    "\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "def load_graph(filename) -> nx.Graph:\n",
    "    with open(filename) as f:\n",
    "        words = f.read().splitlines()\n",
    "\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = pool.map(process_word_neighbours, [(words, word) for word in words])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for result in results:\n",
    "        if result:\n",
    "            G.add_edges_from(result)\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "G = load_graph(\"words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ray.init()\n",
    "print(context.dashboard_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def process_word_neighbours(words, start):\n",
    "    neighbours = []\n",
    "    for word in words:\n",
    "        if edit_distance(start, word) <= 1:\n",
    "            neighbours.append((start, word))\n",
    "\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "def load_graph(filename) -> nx.Graph:\n",
    "    G = nx.Graph()\n",
    "    with open(filename) as f:\n",
    "        words = f.read().splitlines()\n",
    "\n",
    "    results = ray.get([process_word_neighbours.remote(words, word) for word in words])\n",
    "\n",
    "    for result in results:\n",
    "        if result:\n",
    "            G.add_edges_from(result)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Takes about a minute, 3x faster than unparallelised\n",
    "G = load_graph(\"words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
